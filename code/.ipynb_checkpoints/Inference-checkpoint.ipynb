{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qoKyGwt72Twt"
   },
   "source": [
    "## Packages and Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F8uSOTj9pnMk"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from openslide import open_slide, __library_version__ as openslide_version\n",
    "import os\n",
    "from PIL import Image\n",
    "from skimage.color import rgb2gray\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mK9d180N2b9d"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#from tensorflow.keras.applications import VGG16, InceptionV3, VGG19, ResNet50\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pUuXanl3WUg"
   },
   "outputs": [],
   "source": [
    "# Load an example slide and tumor mask\n",
    "\n",
    "def choose_image(image_number):\n",
    "  \n",
    "    global slide_path\n",
    "    global tumor_mask_path\n",
    "    global slide\n",
    "    global tumor_mask\n",
    "\n",
    "    slide_path = os.path.join(SLIDES_DIR, 'tumor_'+image_number+'.tif')\n",
    "    tumor_mask_path =  os.path.join(SLIDES_DIR, 'tumor_'+image_number+'_mask.tif')\n",
    "\n",
    "    slide = open_slide(slide_path)\n",
    "    print (\"Read WSI from %s with width: %d, height: %d\" % (slide_path, \n",
    "                                                          slide.level_dimensions[0][0], \n",
    "                                                          slide.level_dimensions[0][1]))\n",
    "\n",
    "    tumor_mask = open_slide(tumor_mask_path)\n",
    "    print (\"Read tumor mask from %s\" % (tumor_mask_path))\n",
    "\n",
    "    print(\"Slide includes %d levels\", len(slide.level_dimensions))\n",
    "\n",
    "    for i in range(len(slide.level_dimensions)-1):\n",
    "        x = slide.level_dimensions[i][0]\n",
    "        y = slide.level_dimensions[i][1]\n",
    "\n",
    "        print(\"Level %d, dimensions: %s downsample factor %d\" % (i, \n",
    "                                                               slide.level_dimensions[i], \n",
    "                                                               slide.level_downsamples[i]))\n",
    "\n",
    "        downsample = 2**i\n",
    "        dim = 299.\n",
    "\n",
    "        dat.append({'image': image_number, 'level': i, 'downsample factor': downsample, 'x': x, 'y': y, \\\n",
    "                    'max windows': int(round((x*y)/dim**2,0)-1)})\n",
    "        \n",
    "    return slide_path, tumor_mask_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PhTQ5mnF3WUm"
   },
   "outputs": [],
   "source": [
    "# See https://openslide.org/api/python/#openslide.OpenSlide.read_region\n",
    "# Note: x,y coords are with respect to level 0.\n",
    "# There is an example below of working with coordinates\n",
    "# with respect to a higher zoom level.\n",
    "\n",
    "# Read a region from the slide\n",
    "# Return a numpy RBG array\n",
    "\n",
    "def read_slide(slide, x, y, level, width, height, as_float=False):\n",
    "    im = slide.read_region((x,y), level, (width, height))\n",
    "    im = im.convert('RGB') # drop the alpha channel\n",
    "    if as_float:\n",
    "        im = np.asarray(im, dtype=np.float32)\n",
    "    else:\n",
    "        im = np.asarray(im)\n",
    "    assert im.shape == (height, width, 3)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hardcode for consistency. Keras validates on subset of training data, only need holdout for our purposes. \n",
    "train_names = ['tumor_091', 'tumor_002', 'tumor_005', 'tumor_094', 'tumor_078', 'tumor_023', \n",
    "               'tumor_081', 'tumor_001', 'tumor_035', 'tumor_012', 'tumor_057', 'tumor_096', \n",
    "               'tumor_101', 'tumor_031', 'tumor_059', 'tumor_084','tumor_016', 'tumor_064']\n",
    "holdout_names = ['tumor_110', 'tumor_075', 'tumor_019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EKdfd_jx7Gpo"
   },
   "outputs": [],
   "source": [
    "# This will help us exclude valueless data\n",
    "\n",
    "def is_tissue_in_window(image, intensity=0.8):\n",
    "    im_gray = rgb2gray(image)\n",
    "    assert im_gray.shape == (image.shape[0], image.shape[1])\n",
    "    indices = np.where(im_gray <= intensity)\n",
    "    #return zip(indices[0], indices[1])\n",
    "    return len(indices) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "#model = load_model('/domino/datasets/goyetc/medical-imaging/scratch/dense_model_baseline_level_3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to evaluate validation or holdout image\n",
    "Note can definitely consolidate this code with the training data code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5_EeGFtu8x8Y"
   },
   "outputs": [],
   "source": [
    "def run_inference(level, image_name, model, scaling = False):\n",
    "    \n",
    "    #reading in the slides and masks B@ODW\n",
    "    slide_path = os.path.join(SLIDES_DIR, image_name+'.tif')\n",
    "    tumor_mask_path =  os.path.join(SLIDES_DIR, image_name+'_mask.tif')\n",
    "    print(slide_path)\n",
    "    print(tumor_mask_path)\n",
    "\n",
    "    #opening them\n",
    "    print('opening slide & mask..')\n",
    "    slide = open_slide(slide_path)\n",
    "    tumor_mask = open_slide(tumor_mask_path)\n",
    "    \n",
    "    predicted_mask = np.zeros((tumor_mask.level_dimensions[level][1], tumor_mask.level_dimensions[level][0]))\n",
    "    print('predicted mask shape: ' + str(predicted_mask.shape))\n",
    "    \n",
    "    slide_image = read_slide(slide, \n",
    "                         x=0, \n",
    "                         y=0, \n",
    "                         level=level, \n",
    "                         width=slide.level_dimensions[level][0], \n",
    "                         height=slide.level_dimensions[level][1])\n",
    "    # showing the mask for test image at chosen level\n",
    "    mask_image = read_slide(tumor_mask, \n",
    "                        x=0, \n",
    "                        y=0, \n",
    "                        level=level, \n",
    "                        width=tumor_mask.level_dimensions[level][0], \n",
    "                        height=tumor_mask.level_dimensions[level][1])[:,:,0]\n",
    "\n",
    "    #dimensions at chosen level\n",
    "    x_max = int(tumor_mask.level_dimensions[level][0]*.85)\n",
    "    y_max = int(tumor_mask.level_dimensions[level][1]*.85)\n",
    "    \n",
    "    print('y: ' + str(y_max) + ' x: ' + str(x_max))\n",
    "\n",
    "    # choosing downsample factor\n",
    "    downsample_factor = int(slide.level_downsamples[level])\n",
    "\n",
    "    #initiatize coordinates\n",
    "    x0 = int(.15*x_max)\n",
    "    y0 = int(.15*y_max)\n",
    "\n",
    "    #size of window\n",
    "    x_dim, y_dim = 299., 299.\n",
    "    size = (int(x_dim), int(y_dim))\n",
    "\n",
    "    #calculate how many steps we can take with 299x299 window\n",
    "    #x_steps, y_steps = int(((x_max-x0) / x_dim)-1), int(((y_max-y0) / y_dim)-1)\n",
    "    x_steps, y_steps = int(((x_max-x0) / x_dim)), int(((y_max-y0) / y_dim)) # I don't think we need the -1 above since int() already rounds down\n",
    "    print('x steps: '+ str(x_steps) + ' y steps: '+ str(y_steps))\n",
    "\n",
    "    for i in range(x_steps):\n",
    "        \n",
    "        # reset y0 to start\n",
    "        y0 = int(.15*y_max)\n",
    "        \n",
    "        for j in range(y_steps): \n",
    "            #generating a window from the original slide\n",
    "            window = read_slide(slide, \n",
    "                             x=int(x0)*downsample_factor, \n",
    "                             y=int(y0)*downsample_factor, \n",
    "                             level=level, \n",
    "                             width=int(x_dim), \n",
    "                             height=int(y_dim))\n",
    "\n",
    "            if is_tissue_in_window(window) is True:\n",
    "                window_reshaped = window.reshape(1, 299, 299, 3)\n",
    "                \n",
    "                if scaling == True:\n",
    "                    window_reshaped = window_reshaped / 255 # scaling\n",
    "                \n",
    "                pred = model.predict(window_reshaped)\n",
    "            \n",
    "                if pred > 0.5:\n",
    "                    predicted_mask[int(x0):(int(x0) + int(x_dim)), int(y0):(int(y0) + int(y_dim))] = 1\n",
    "\n",
    "            #move the sliding window on y axis\n",
    "            y0 = y0 + y_dim\n",
    "\n",
    "        #move the sliding window on x axis\n",
    "        x0 = x0 + x_dim\n",
    "       \n",
    "    return predicted_mask, slide_image, mask_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLIDES_DIR = '/domino/datasets/local/med_images/slides'\n",
    "#print(\"Slides path within the drive: {}\".format(SLIDES_DIR))\n",
    "#holdout_names = ['tumor_110', 'tumor_075', 'tumor_019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tumor_001_mask.tif  tumor_019.tif\ttumor_059.xml\t    tumor_091_mask.tif\n",
      "tumor_001.tif\t    tumor_019.xml\ttumor_064_mask.tif  tumor_091.tif\n",
      "tumor_001.xml\t    tumor_023_mask.tif\ttumor_064.tif\t    tumor_091.xml\n",
      "tumor_002_mask.tif  tumor_023.tif\ttumor_064.xml\t    tumor_094_mask.tif\n",
      "tumor_002.tif\t    tumor_023.xml\ttumor_075_mask.tif  tumor_094.tif\n",
      "tumor_002.xml\t    tumor_031_mask.tif\ttumor_075.tif\t    tumor_094.xml\n",
      "tumor_005_mask.tif  tumor_031.tif\ttumor_075.xml\t    tumor_096_mask.tif\n",
      "tumor_005.tif\t    tumor_031.xml\ttumor_078_mask.tif  tumor_096.tif\n",
      "tumor_005.xml\t    tumor_035_mask.tif\ttumor_078.tif\t    tumor_096.xml\n",
      "tumor_012_mask.tif  tumor_035.tif\ttumor_078.xml\t    tumor_101_mask.tif\n",
      "tumor_012.tif\t    tumor_035.xml\ttumor_081_mask.tif  tumor_101.tif\n",
      "tumor_012.xml\t    tumor_057_mask.tif\ttumor_081.tif\t    tumor_101.xml\n",
      "tumor_016_mask.tif  tumor_057.tif\ttumor_081.xml\t    tumor_110_mask.tif\n",
      "tumor_016.tif\t    tumor_057.xml\ttumor_084_mask.tif  tumor_110.tif\n",
      "tumor_016.xml\t    tumor_059_mask.tif\ttumor_084.tif\t    tumor_110.xml\n",
      "tumor_019_mask.tif  tumor_059.tif\ttumor_084.xml\n"
     ]
    }
   ],
   "source": [
    "!ls $SLIDES_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inf = load_model('/domino/datasets/goyetc/medical-imaging/scratch/dense_model_baseline_level_3.h5')\n",
    "image_selected = random.choice(holdout_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "p2qdKVLt12At",
    "outputId": "16dfea5e-3e2b-42a8-88b8-3a03bb93e533",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/domino/datasets/local/med_images/slides/tumor_019.tif\n",
      "/domino/datasets/local/med_images/slides/tumor_019_mask.tif\n",
      "opening slide & mask..\n",
      "predicted mask shape: (27456, 12224)\n",
      "y: 23337 x: 10390\n",
      "x steps: 29 y steps: 66\n"
     ]
    }
   ],
   "source": [
    "predicted_mask, slide_image, mask_image = run_inference(3, image_selected, model = model_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "colab_type": "code",
    "id": "UbDK9BLz12Av",
    "outputId": "676e8688-bc9b-4b10-eb11-d0d151931916"
   },
   "outputs": [],
   "source": [
    "# show inference results\n",
    "plt.figure(figsize=(10,10), dpi=100)\n",
    "plt.imshow(slide_image)\n",
    "plt.imshow(mask_image, cmap='OrRd', alpha=0.5)\n",
    "plt.imshow(predicted_mask, cmap='OrRd', alpha=0.3)\n",
    "fig4 = plt.gcf()\n",
    "fig4.savefig('/mnt/results/inference_prediction_example_baseline_level_3_'+str(image_selected+'.png'), dpi = 100)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "1LKCgkxPeHv8",
    "Hqaax03mTPz3",
    "eRyN99iATYYa",
    "5oIyG0quK21H",
    "w9FEuM6gIRwK",
    "I7mrk_54LiSb",
    "by0-mL7pIOjf",
    "DNvHbrbudM1g",
    "x-RorUsWCE7_",
    "eojNb92c0o1y",
    "WF4oNlzdZqDG",
    "RYreYUDxudip"
   ],
   "name": "ADL_Final_Project_temp.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
